**Github Link:** https://github.com/ravi-ivar-7/hilabs

# HiLabs Hackathon 2025: Healthcare Contract Language Classification

## Author
- **Name:** Ravi Kumar
- **GitHub:** [@ravi-ivar-7](https://github.com/ravi-ivar-7)
- **Institution:** IIT Kharagpur
- **Team:** retrostoat

## Development Environment
- **OS**: Linux 6.14.0-29-generic #29~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC x86_64
- **CPU**: 12th Gen Intel(R) Core(TM) i5-1240P
- **RAM**: 7.4Gi total
- **Node.js**: v20.16.0
- **Python**: 3.12.3
- **Docker**: 28.4.0

## Table of Contents
1. [Quick Setup](#quick-setup)
2. [Approach & Methodology](#approach--methodology)
3. [System Architecture](#system-architecture)
4. [Processing Pipeline](#processing-pipeline)

![System Screenshot](data/Screenshot%20from%202025-09-29%2023-44-29.png)

## Demo Video
[![Demo Video](data/Screenshot%20from%202025-09-29%2023-44-29.png)](data/Hilabs%20demo.mp4)

*Click the image above to view the demo video*

## Quick Setup

### Prerequisites
- Docker and Docker Compose installed
- Git (for cloning the repository)
- 8GB+ RAM recommended

### Installation Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/ravi-ivar-7/hilabs.git
   cd hilabs
   ```

2. **Choose your setup method:**

#### Option A: Local Development Setup (Recommended)
```bash
# Copy environment configuration
cp .env.example .env

# Start all services locally
./services.sh start
```

**Access the application:**
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs

#### Option B: Docker Setup
```bash
docker-compose up --build
```

**Access the application:**
- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs

**Note**: Docker may take some time to build and start all services (backend, frontend, worker, Redis). Please be patient during the initial setup. ğŸ˜Š
- **Backend API**: http://localhost:8000
- **Redis**: localhost:6379

# Approach & Methodology

## Problem Statement
```
Healthcare Contract Analysis Challenge:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Healthcare contract PDFs (TN/WA states)              â”‚
â”‚                                                             â”‚
â”‚ GOAL: Classify clauses as Standard/Non-Standard/Ambiguous   â”‚
â”‚                                                             â”‚
â”‚ METHOD: Compare against state-specific template standards   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Target Attributes (5 Key Healthcare Clauses)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Attribute           â”‚ Description                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Medicaid Timely     â”‚ Claims submission deadlines (120 days)  â”‚
â”‚ Filing              â”‚                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Medicare Timely     â”‚ Medicare claims deadlines (365 days)   â”‚
â”‚ Filing              â”‚                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ No Steerage/SOC     â”‚ Network participation rules             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Medicaid Fee        â”‚ Payment methodology for Medicaid       â”‚
â”‚ Schedule            â”‚                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Medicare Fee        â”‚ Payment methodology for Medicare       â”‚
â”‚ Schedule            â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Classification Methodology Overview
```
Multi-Step Analysis Approach:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Exception Detection â†’ Conditional clauses = NON-STANDARD â”‚
â”‚ 2. Exact Text Matching â†’ Perfect match = STANDARD          â”‚
â”‚ 3. Placeholder Substitution â†’ Structure match = STANDARD   â”‚
â”‚ 4. Fuzzy String Matching â†’ 70%+ similarity = STANDARD      â”‚
â”‚ 5. Semantic Analysis â†’ SBERT embeddings for meaning        â”‚
â”‚ 6. Methodology Detection â†’ Different methods = NON-STANDARD â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

*Detailed implementation flowchart available below in Processing Pipeline section*
```

## Core Technologies
```
AI/ML Components:
â€¢ spaCy NLP â†’ Text processing and analysis
â€¢ SBERT â†’ Semantic similarity embeddings  
â€¢ RapidFuzz â†’ Lexical string matching
â€¢ Local Models â†’ No external API dependencies

*Full technical architecture details above in System Architecture section*
```

## Placeholder Normalization
```
Variable Content Handling:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Original: "Provider accepts 95% of eligible charges"       â”‚
â”‚ Template: "Provider accepts XX% of eligible charges"       â”‚
â”‚                                                             â”‚
â”‚ Normalization Process:                                      â”‚
â”‚ 1. Replace "95%" â†’ "<PCT>"                                 â”‚
â”‚ 2. Replace "XX%" â†’ "<PCT>"                                 â”‚
â”‚ 3. Compare normalized versions                              â”‚
â”‚ 4. Match: STANDARD classification                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Placeholder Patterns:
â€¢ <PCT>: Percentages (95%, XX%, one hundred percent)
â€¢ <ORG>: Organizations (Plan, Company, Network)
â€¢ <MEMBER>: Member types (Enrollee, Subscriber)
â€¢ <DATE>: Dates and timeframes
â€¢ <FEE_SCHEDULE>: Payment references
```

## Semantic Understanding Approach
```
Meaning-Based Classification:
â€¢ SBERT embeddings capture clause intent beyond exact wording
â€¢ Cosine similarity measures semantic closeness to templates
â€¢ Configurable thresholds balance precision vs coverage
â€¢ Handles paraphrased clauses with same legal meaning

*Implementation details and thresholds below in Processing Pipeline section*
```

## Human-in-the-Loop System
```
Feedback Loop:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ambiguous       â”‚â”€â”€â”€â–¶â”‚ Human Review    â”‚â”€â”€â”€â–¶â”‚ Corrected       â”‚
â”‚ Classification  â”‚    â”‚ Interface       â”‚    â”‚ Classification  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Show clause +   â”‚    â”‚ User selects    â”‚    â”‚ Store feedback  â”‚
â”‚ template match  â”‚    â”‚ correct class   â”‚    â”‚ for learning    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## Innovation & Compliance
```
Key Innovations:
âœ“ Multi-step classification combining lexical + semantic analysis
âœ“ State-specific template management (TN/WA)
âœ“ Advanced placeholder normalization
âœ“ Local AI processing (no external APIs)
âœ“ Real-time progress tracking
âœ“ Human-in-the-loop feedback system
âœ“ Local data processing only
```

# System Architecture

## System Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Frontend     â”‚    â”‚    Backend      â”‚    â”‚     Worker      â”‚    â”‚  Classification â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   (Celery)      â”‚â—„â”€â”€â–ºâ”‚    Engine       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚   (spaCy+SBERT) â”‚
â”‚ â€¢ Upload UI     â”‚    â”‚ â€¢ REST API      â”‚    â”‚ â€¢ Async Tasks   â”‚    â”‚ â€¢ NLP Models    â”‚
â”‚ â€¢ Dashboard     â”‚    â”‚ â€¢ Database      â”‚    â”‚ â€¢ Redis Queue   â”‚    â”‚ â€¢ Templates     â”‚
â”‚ â€¢ Results       â”‚    â”‚ â€¢ File Storage  â”‚    â”‚ â€¢ Processing    â”‚    â”‚ â€¢ Classificationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      :3000                   :8000                 Redis:6379              Local AI
```

## Component Details

### 1. Frontend (Next.js/TypeScript)
```
Pages:
â”œâ”€â”€ / (Home)
â”œâ”€â”€ /upload (PDF Upload)
â””â”€â”€ /analysis (Results, Analysis & Review Dashboard)
    â”œâ”€â”€ Results Display
    â”œâ”€â”€ Classification Analysis
    â””â”€â”€ Human Feedback Modals

Tech Stack:
â€¢ Next.js
â€¢ TypeScript + Tailwind CSS
â€¢ Real-time status updates
```

### 2. Backend (FastAPI)
```
API Endpoints:
â”œâ”€â”€ POST /api/v1/contracts/upload
â”œâ”€â”€ GET  /api/v1/contracts/{id}/status
â”œâ”€â”€ GET  /api/v1/contracts/{id}/results
â”œâ”€â”€ GET  /api/v1/contracts/{id} (contract details)
â”œâ”€â”€ POST /api/v1/contracts/clauses/feedback
â”œâ”€â”€ GET  /api/v1/health (health check)
â””â”€â”€ GET  /docs (Swagger UI)

Database Tables:
â”œâ”€â”€ Contract (main contract data + processing status)
â”œâ”€â”€ FileRecord (file storage tracking)
â”œâ”€â”€ ContractClause (classified clauses + confidence scores)
â”œâ”€â”€ ProcessingLog (audit trail + component logging)
â””â”€â”€ ClauseFeedback (human corrections + ratings)
```

### 3. Worker Services (Celery + Redis)
```
Task Queue Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Upload    â”‚â”€â”€â”€â–ºâ”‚    Redis    â”‚â”€â”€â”€â–ºâ”‚   Worker    â”‚
â”‚   Request   â”‚    â”‚   Message   â”‚    â”‚  Processes  â”‚
â”‚             â”‚    â”‚   Broker    â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Result     â”‚
                   â”‚  Backend    â”‚
                   â”‚  Storage    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Classification Engine
```
NLP Pipeline:
PDF â†’ PyMuPDF â†’ Text Cleaning â†’ Clause Extraction â†’ spaCy Analysis â†’ SBERT Similarity â†’ Classification

Models Used:
â€¢ spaCy: en_core_web_sm (NLP pipeline)
â€¢ SBERT: all-MiniLM-L6-v2 (semantic similarity)
â€¢ RapidFuzz: string matching
â€¢ Local processing (no external APIs)
```

## Data Flow Diagram
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Upload â”‚
â”‚ PDF + State â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend   â”‚â”€â”€â”€â”€â–ºâ”‚  Backend    â”‚â”€â”€â”€â”€â–ºâ”‚   Celery    â”‚
â”‚  Validation â”‚     â”‚  File Save  â”‚     â”‚   Queue     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database   â”‚â—„â”€â”€â”€â”€â”‚   Results   â”‚â—„â”€â”€â”€â”€â”‚ Stage 1+2   â”‚
â”‚   Storage   â”‚     â”‚  Assembly   â”‚     â”‚ Processing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## File Storage Structure
```
upload/
â”œâ”€â”€ contracts-tn/
â”‚   â”œâ”€â”€ {uuid}.pdf                    # Original PDF
â”‚   â”œâ”€â”€ {uuid}_clauses.json          # Extracted clauses
â”‚   â””â”€â”€ {uuid}_results.json          # Classification results
â””â”€â”€ contracts-wa/
    â”œâ”€â”€ {uuid}.pdf
    â”œâ”€â”€ {uuid}_clauses.json
    â””â”€â”€ {uuid}_results.json
```

### Docker Architecture & Scalability Design
```
docker-compose.yml:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  frontend   â”‚  â”‚  backend    â”‚  â”‚   worker    â”‚  â”‚   redis     â”‚
â”‚   :3000     â”‚  â”‚   :8000     â”‚  â”‚  (celery)   â”‚  â”‚   :6379     â”‚
â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚
â”‚ Next.js     â”‚  â”‚ FastAPI     â”‚  â”‚ Processing  â”‚  â”‚ Redis       â”‚
â”‚ React UI    â”‚  â”‚ SQLite DB   â”‚  â”‚ Pipeline    â”‚  â”‚ Message     â”‚
â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚ Broker      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                â”‚
                   hilabs-network (bridge)
                   
Shared Volumes:
â€¢ backend_data (SQLite DB + app data)
â€¢ worker_uploads (PDF files + processing results)  
â€¢ redis_data (Redis persistence)

Scaling Strategy (code can be extended):
â€¢ Worker containers are the primary bottleneck (NLP processing: 30-120 sec)
â€¢ Horizontal scaling: docker-compose scale worker=N based on Redis queue depth
â€¢ Resource allocation: Worker (2 CPU, 4GB) > Backend (1 CPU, 1GB) > Frontend (0.5 CPU, 512MB)
â€¢ Auto-scaling triggers: Queue depth >50 tasks â†’ scale up, <10 tasks â†’ scale down
â€¢ Current: Single worker container, extensible to multi-worker deployment
```


# Processing Pipeline

## Pipeline Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Upload    â”‚â”€â”€â”€â–¶â”‚   Stage 1   â”‚â”€â”€â”€â–¶â”‚   Stage 2   â”‚â”€â”€â”€â–¶â”‚   Results   â”‚
â”‚   PDF File  â”‚    â”‚Preprocessingâ”‚    â”‚Classificationâ”‚    â”‚  Dashboard  â”‚
â”‚             â”‚    â”‚             â”‚    â”‚             â”‚    â”‚             â”‚
â”‚ â€¢ File      â”‚    â”‚ â€¢ Extract   â”‚    â”‚ â€¢ Template  â”‚    â”‚ â€¢ Standard  â”‚
â”‚ â€¢ State     â”‚    â”‚ â€¢ Clean     â”‚    â”‚ â€¢ Compare   â”‚    â”‚ â€¢ Non-Std   â”‚
â”‚ â€¢ Validate  â”‚    â”‚ â€¢ Clauses   â”‚    â”‚ â€¢ Classify  â”‚    â”‚ â€¢ Ambiguous â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Frontend           Celery Task       Celery Task        Frontend
```

## Stage 1: Preprocessing
```
Input: PDF Contract + State (TN/WA)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PDF Upload  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 20% - Loading PDF
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    PyMuPDF Extraction
â”‚ Text Extractâ”‚â”€â”€â”€â–º Raw Text + Metadata
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    Fallback Methods
       â”‚ 60% - Cleaning Text  
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Remove Artifacts
â”‚ Text Clean  â”‚â”€â”€â”€â–º Normalized Text
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    UTF-8 Encoding
       â”‚ 70% - Extracting Clauses
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Sentence Splitting
â”‚ Clause      â”‚â”€â”€â”€â–º Clause List + IDs
â”‚ Extraction  â”‚    Context Preservation
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 90% - Saving Data
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    JSON Serialization
â”‚ Data Store  â”‚â”€â”€â”€â–º {id}_clauses.json
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    Database Records
       â”‚ 100% - Complete
       â–¼
    Queue Stage 2
```

## Stage 2: Classification
```
Input: Clause Data + Templates
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Data   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 20% - Loading Templates
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    State Detection (TN/WA)
â”‚ Template    â”‚â”€â”€â”€â–º Load State Templates
â”‚ Loading     â”‚    Initialize NLP Models
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 40% - Starting Classification
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    6-Step Analysis
â”‚ Classify    â”‚â”€â”€â”€â–º Standard/Non-Standard/Ambiguous
â”‚ Clauses     â”‚    Confidence Scoring
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 80% - Saving Results
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Database Storage
â”‚ Store       â”‚â”€â”€â”€â–º {id}_results.json
â”‚ Results     â”‚    Audit Logs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 100% - Complete
       â–¼
    Results Ready
```

## 6-Step Classification Method
```
For Each Clause:

Step 1: Exception Check
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scan for: "except", "unless",      â”‚ â”€â”€â–º Non-Standard
â”‚ "provided that", "subject to"      â”‚     (90% confidence)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Exact Match
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Normalized text == Template text    â”‚ â”€â”€â–º Standard
â”‚ (case insensitive, whitespace)     â”‚     (99% confidence)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 3: Placeholder Substitution
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Replace variables: %,dates,names    â”‚ â”€â”€â–º Standard
â”‚ Check structure similarity          â”‚     (95% confidence)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 4: Fuzzy Matching
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RapidFuzz string similarity         â”‚ â”€â”€â–º Standard
â”‚ Threshold: 70%                      â”‚     (90% confidence)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 5: Semantic Similarity
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SBERT embeddings + cosine similarityâ”‚
â”‚ â‰¥60%: Standard (85% confidence)     â”‚ â”€â”€â–º Standard/Ambiguous
â”‚ 50-70%: Ambiguous                   â”‚     
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 6: Methodology Detection
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Check for different payment methods â”‚ â”€â”€â–º Non-Standard
â”‚ "medicare rate", "billed charge"    â”‚     (85% confidence)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â–¶â”‚   Celery    â”‚
â”‚   Upload    â”‚    â”‚   Backend   â”‚    â”‚   Worker    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SQLite    â”‚â—„â”€â”€â”€â”‚   Results   â”‚â—„â”€â”€â”€â”‚ spaCy+SBERT â”‚
â”‚  Database   â”‚    â”‚  Assembly   â”‚    â”‚ Classifier  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## File Processing Flow
```
upload/contracts-{state}/
â”œâ”€â”€ {uuid}.pdf                 â—„â”€â”€â”€ Original upload
â”œâ”€â”€ {uuid}_clauses.json        â—„â”€â”€â”€ Stage 1 output
â””â”€â”€ {uuid}_results.json        â—„â”€â”€â”€ Stage 2 output

Database Flow:
Contract Table â”€â”€â–º ProcessingLog â”€â”€â–º ContractClause â”€â”€â–º ClauseFeedback
     â”‚                  â”‚                  â”‚                â”‚
   Status            Audit Trail      Classifications   Human Feedback
```

## Progress Tracking
```
Stage 1 Progress:
0% â”€â”€â–º 20% â”€â”€â–º 60% â”€â”€â–º 70% â”€â”€â–º 90% â”€â”€â–º 100%
â”‚      â”‚       â”‚       â”‚       â”‚       â”‚
â”‚      â”‚       â”‚       â”‚       â”‚       â””â”€ Data Saved
â”‚      â”‚       â”‚       â”‚       â””â”€ JSON Export
â”‚      â”‚       â”‚       â””â”€ Clause Extraction
â”‚      â”‚       â””â”€ Text Cleaning
â”‚      â””â”€ PDF Loading
â””â”€ Task Started

Stage 2 Progress:
0% â”€â”€â–º 20% â”€â”€â–º 40% â”€â”€â–º 60% â”€â”€â–º 80% â”€â”€â–º 100%
â”‚      â”‚       â”‚       â”‚       â”‚       â”‚
â”‚      â”‚       â”‚       â”‚       â”‚       â””â”€ Results Saved
â”‚      â”‚       â”‚       â”‚       â””â”€ Database Storage
â”‚      â”‚       â”‚       â””â”€ Classification
â”‚      â”‚       â””â”€ Template Loading
â”‚      â””â”€ Data Loading
â””â”€ Task Started
```

## Error Handling
```
Error Types:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PDF Corrupt â”‚    â”‚ NLP Model   â”‚    â”‚ Database    â”‚
â”‚ File Issues â”‚    â”‚ Load Failed â”‚    â”‚ Connection  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
       â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Retry with  â”‚    â”‚ Fallback to â”‚    â”‚ Retry with  â”‚
â”‚ Alternative â”‚    â”‚ Basic NLP   â”‚    â”‚ Backoff     â”‚
â”‚ Extraction  â”‚    â”‚ Processing  â”‚    â”‚ Strategy    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## Accuracy & Validation Methodology

### Systematic Validation Approach

#### 1. Template vs Template Baseline Testing
- Used actual template PDFs as ground truth
- Tested template clauses against themselves to establish baseline accuracy
- Template clauses are **pre-extracted** and hardcoded in `worker/classification_parameters.py`
- This eliminates content variation and focuses purely on algorithm performance


#### 2. Real PDF Content Extraction
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Contract PDFs  â”‚â”€â”€â”€â–¶â”‚ PDF Text Extraction â”‚â”€â”€â”€â–¶â”‚ Extracted Clauses   â”‚
â”‚ (Upload via UI)     â”‚    â”‚ â€¢ pdfplumber (1st)  â”‚    â”‚ (Dynamic parsing)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ PyPDF2 (fallback)â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ â€¢ Robust extraction â”‚              â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Static Templates    â”‚                               â”‚ Classification      â”‚
â”‚ â€¢ TN_TEMPLATE_      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ â€¢ Fuzzy matching    â”‚
â”‚   CLAUSES (5 attrs) â”‚                               â”‚ â€¢ Semantic analysis â”‚
â”‚ â€¢ WA_TEMPLATE_      â”‚                               â”‚ â€¢ Multi-step logic  â”‚
â”‚   CLAUSES (5 attrs) â”‚                               â”‚ â€¢ Confidence scores â”‚
â”‚ â€¢ Hardcoded in code â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
                                                                â–¼
                                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                      â”‚ Dual Storage        â”‚
                                                      â”‚ â€¢ Database records  â”‚
                                                      â”‚ â€¢ JSON backup files â”‚
                                                      â”‚ â€¢ Audit trails     â”‚
                                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data-Driven Performance Tracking

#### Quantifiable Improvements:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Attribute           â”‚ Before  â”‚ After   â”‚ Improvement Method      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ WA Medicare Timely  â”‚   0%    â”‚  40%    â”‚ Added XX-day language   â”‚
â”‚ WA Medicaid Fee     â”‚  11%    â”‚  21%    â”‚ Structure alignment     â”‚
â”‚ WA No Steerage/SOC  â”‚   4%    â”‚   9%    â”‚ Added legal phrases     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Iterative Accuracy Improvements

#### Classification Parameter Optimization:
Based on systematic testing and validation results, the `worker/classification_parameters.py` file has been continuously updated to improve classification accuracy:

**Key Improvements Made:**
- **Threshold Tuning**: Adjusted fuzzy matching threshold to 70% and semantic similarity to 0.60 based on real-world performance
- **Template Clause Refinement**: Updated actual template clauses extracted from TN/WA PDFs for better matching
- **Exception Token Expansion**: Added comprehensive list of conditional clause indicators
- **Placeholder Normalization**: Enhanced pattern matching for variables like percentages, dates, and organization names
- **State-Specific Optimization**: Separate template sets for TN and WA with state-specific legal language

**Configuration Structure:**
```python
# worker/classification_parameters.py - Centralized Configuration

# Classification thresholds (optimized through testing)
FUZZY_THRESHOLD = 70          # RapidFuzz similarity threshold
SBERT_THRESHOLD = 0.60        # SBERT semantic similarity threshold
SBERT_AMBIG_LOW = 0.50        # Lower bound for ambiguous classification
SBERT_AMBIG_HIGH = 0.70       # Upper bound for ambiguous classification

# Template clauses (5 attributes per state)
TN_TEMPLATE_CLAUSES = {
    "Medicaid Timely Filing": "...",
    "Medicare Timely Filing": "...",
    "Medicaid Fee Schedule": "...",
    "Medicare Fee Schedule": "...",
    "No Steerage/SOC": "..."
}

WA_TEMPLATE_CLAUSES = {
    # Same 5 attributes with state-specific content
}

# Exception detection
EXCEPTION_TOKENS = ['except', 'unless', 'provided that', ...]

# Text normalization patterns
PLACEHOLDER_MAP = {
    r"\b\d{1,3}\s*%\b": "<PCT>",
    r"\b(Fee\s+Schedule|Compensation\s+Schedule)\b": "<FEE_SCHEDULE>",
    # ... 20+ normalization patterns
}
```

**Performance Impact:**
- **WA Medicare Timely Filing**: 0% â†’ 40% accuracy improvement
- **WA Medicaid Fee Schedule**: 11% â†’ 21% accuracy improvement  
- **WA No Steerage/SOC**: 4% â†’ 9% accuracy improvement
- **Overall System**: Consistent 85%+ confidence scores on standard clauses

This centralized parameter approach allows for rapid iteration and testing of classification improvements without code changes.